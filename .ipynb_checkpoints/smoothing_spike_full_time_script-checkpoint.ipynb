{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{L}[1]{\\| #1 \\|}\\newcommand{VL}[1]{\\L{ \\vec{#1} }}\\newcommand{R}[1]{\\operatorname{Re}\\,(#1)}\\newcommand{I}[1]{\\operatorname{Im}\\, (#1)}$\n",
    "\n",
    "## An introduction to smoothing\n",
    "\n",
    "Smoothing is a process by which data points are averaged with their neighbors\n",
    "in a series, such as a time series, or image. This (usually) has the effect of\n",
    "blurring the sharp edges in the smoothed data.  Smoothing is sometimes\n",
    "referred to as filtering, because smoothing has the effect of suppressing high\n",
    "frequency signal and enhancing low frequency signal. There are many different\n",
    "methods of smoothing, but here we discuss smoothing with a Gaussian kernel. We\n",
    "hope we will succeed in explaining this phrase in the explanation below.\n",
    "\n",
    "### Some example data for smoothing\n",
    "\n",
    "First we load and configure the libraries we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Make numpy print 4 significant digits for prettiness\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "np.random.seed(5) # To get predictable random numbers\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.animation as animation\n",
    "from sklearn import datasets  # to retrieve the iris Dataset\n",
    "import pandas as pd  # to load the dataframe\n",
    "from sklearn.preprocessing import StandardScaler  # to standardize the features\n",
    "from sklearn.decomposition import PCA  # to apply PCA\n",
    "import seaborn as sns  # to plot the heat maps#float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a set of data, made out of random numbers, that we will use as a\n",
    "pretend time series, or a single line of data from one plane of an\n",
    "image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 115379)\n"
     ]
    }
   ],
   "source": [
    "# Load spike data\n",
    "spike_data = np.load('data/spikes_v1_clean.npy')                      \n",
    "print(np.shape(spike_data))\n",
    "time = 50000\n",
    "spike_data_short = spike_data[:,0:time]\n",
    "# short time span\n",
    "t = np.shape(spike_data_short)[1]\n",
    "n = np.shape(spike_data_short)[0]\n",
    "\n",
    "n_y = np.arange(n)\n",
    "t_x = np.arange(t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_spike = spike_data_short\n",
    "#t_full = np.linspace(1, t, t)\n",
    "#t_x = np.arange(length)\n",
    "#n_y = np.shape(y_spike)[0]\n",
    "\n",
    "#plt.bar(t_x,y_spike[0,0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwhm2sigma(fwhm):\n",
    "    return fwhm / np.sqrt(8 * np.log(2))\n",
    "def sigma2fwhm(sigma):\n",
    "    return sigma * np.sqrt(8 * np.log(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning parameter\n",
    "FWHM = 20\n",
    "sigma = fwhm2sigma(FWHM)\n",
    "#x_position = 100 # 14th point\n",
    "#kernel_at_pos_n = np.exp(-(t_x - x_position) ** 2 / (2 * sigma ** 2))\n",
    "#kernel_at_pos_n = kernel_at_pos_n / sum(kernel_at_pos_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_vals_spike_full = np.zeros(y_spike.shape)\n",
    "for nn in n_y:\n",
    "    #smoothed_vals_spike = np.zeros(y_spike[nn,:].shape)\n",
    "    #print(nn)\n",
    "\n",
    "    for x_position in t_x:\n",
    "        kernel = np.exp(-(t_x - x_position) ** 2 / (2 * sigma ** 2))\n",
    "        kernel = kernel / sum(kernel)\n",
    "        smoothed_vals_spike_full[nn,x_position] = sum(y_spike[nn,:] * kernel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_smooth_W20L50k', smoothed_vals_spike_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
